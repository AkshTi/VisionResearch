=========================================
Step 1: Generate Videos with DFoT
Action-Video Mismatch Experiment
=========================================

Job ID: 9246188
Node: node3407
Start time: Sat Feb 14 20:20:08 EST 2026
GPU: 0,1

Python: /home/akshatat/.conda/envs/mech_interp_gpu/bin/python
Python version: Python 3.10.19

Checking GPU availability...
Sat Feb 14 20:20:11 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 590.48.01              Driver Version: 590.48.01      CUDA Version: 13.1     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA L40S                    On  |   00000000:CA:00.0 Off |                    0 |
| N/A   30C    P8             33W /  350W |       0MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA L40S                    On  |   00000000:E1:00.0 Off |                    0 |
| N/A   30C    P8             34W /  350W |       0MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

=========================================
Starting DFoT video generation...
=========================================

============================================================
STEP 1: Generate videos with DFoT
============================================================

[Preflight]

[RUN]
  cwd: diffusion-forcing-transformer
  cmd: python -c import main; print('ok')
[Warn] DFOT_CHECKPOINT looks like a file/path but does not exist: DFoT_RE10K.ckpt
      If you intended pretrained name (e.g. DFoT_RE10K.ckpt), set it exactly like DFoT wiki uses.

[RUN]
  cwd: diffusion-forcing-transformer
  cmd: python -m main +name=action_mismatch_step1 dataset_experiment=realestate10k_mini_video_generation load=pretrained:DFoT_RE10K.ckpt wandb.mode=offline wandb.entity=akshatatiwari55 algorithm.checkpoint.strict=False experiment.tasks=[validation] experiment.validation.data.shuffle=False experiment.validation.batch_size=1 dataset.context_length=4 dataset.frame_skip=20 dataset.n_frames=12 dataset.num_eval_videos=5 algorithm.tasks.prediction.history_guidance.name=vanilla +algorithm.tasks.prediction.history_guidance.guidance_scale=4.0

[DFoT FAILED]
stdout (tail):
 n_model.model.dit_base.blocks.7.norm2.modulation.1.bias', 'diffusion_model.model.dit_base.blocks.7.mlp.fc1.weight', 'diffusion_model.model.dit_base.blocks.7.mlp.fc1.bias', 'diffusion_model.model.dit_base.blocks.7.mlp.fc2.weight', 'diffusion_model.model.dit_base.blocks.7.mlp.fc2.bias', 'diffusion_model.model.dit_base.blocks.8.norm1.modulation.1.weight', 'diffusion_model.model.dit_base.blocks.8.norm1.modulation.1.bias', 'diffusion_model.model.dit_base.blocks.8.attn.qkv.weight', 'diffusion_model.model.dit_base.blocks.8.attn.qkv.bias', 'diffusion_model.model.dit_base.blocks.8.attn.proj.weight', 'diffusion_model.model.dit_base.blocks.8.attn.proj.bias', 'diffusion_model.model.dit_base.blocks.8.norm2.modulation.1.weight', 'diffusion_model.model.dit_base.blocks.8.norm2.modulation.1.bias', 'diffusion_model.model.dit_base.blocks.8.mlp.fc1.weight', 'diffusion_model.model.dit_base.blocks.8.mlp.fc1.bias', 'diffusion_model.model.dit_base.blocks.8.mlp.fc2.weight', 'diffusion_model.model.dit_base.blocks.8.mlp.fc2.bias', 'diffusion_model.model.dit_base.blocks.9.norm1.modulation.1.weight', 'diffusion_model.model.dit_base.blocks.9.norm1.modulation.1.bias', 'diffusion_model.model.dit_base.blocks.9.attn.qkv.weight', 'diffusion_model.model.dit_base.blocks.9.attn.qkv.bias', 'diffusion_model.model.dit_base.blocks.9.attn.proj.weight', 'diffusion_model.model.dit_base.blocks.9.attn.proj.bias', 'diffusion_model.model.dit_base.blocks.9.norm2.modulation.1.weight', 'diffusion_model.model.dit_base.blocks.9.norm2.modulation.1.bias', 'diffusion_model.model.dit_base.blocks.9.mlp.fc1.weight', 'diffusion_model.model.dit_base.blocks.9.mlp.fc1.bias', 'diffusion_model.model.dit_base.blocks.9.mlp.fc2.weight', 'diffusion_model.model.dit_base.blocks.9.mlp.fc2.bias', 'diffusion_model.model.dit_base.blocks.10.norm1.modulation.1.weight', 'diffusion_model.model.dit_base.blocks.10.norm1.modulation.1.bias', 'diffusion_model.model.dit_base.blocks.10.attn.qkv.weight', 'diffusion_model.model.dit_base.blocks.10.attn.qkv.bias', 'diffusion_model.model.dit_base.blocks.10.attn.proj.weight', 'diffusion_model.model.dit_base.blocks.10.attn.proj.bias', 'diffusion_model.model.dit_base.blocks.10.norm2.modulation.1.weight', 'diffusion_model.model.dit_base.blocks.10.norm2.modulation.1.bias', 'diffusion_model.model.dit_base.blocks.10.mlp.fc1.weight', 'diffusion_model.model.dit_base.blocks.10.mlp.fc1.bias', 'diffusion_model.model.dit_base.blocks.10.mlp.fc2.weight', 'diffusion_model.model.dit_base.blocks.10.mlp.fc2.bias', 'diffusion_model.model.dit_base.blocks.11.norm1.modulation.1.weight', 'diffusion_model.model.dit_base.blocks.11.norm1.modulation.1.bias', 'diffusion_model.model.dit_base.blocks.11.attn.qkv.weight', 'diffusion_model.model.dit_base.blocks.11.attn.qkv.bias', 'diffusion_model.model.dit_base.blocks.11.attn.proj.weight', 'diffusion_model.model.dit_base.blocks.11.attn.proj.bias', 'diffusion_model.model.dit_base.blocks.11.norm2.modulation.1.weight', 'diffusion_model.model.dit_base.blocks.11.norm2.modulation.1.bias', 'diffusion_model.model.dit_base.blocks.11.mlp.fc1.weight', 'diffusion_model.model.dit_base.blocks.11.mlp.fc1.bias', 'diffusion_model.model.dit_base.blocks.11.mlp.fc2.weight', 'diffusion_model.model.dit_base.blocks.11.mlp.fc2.bias', 'diffusion_model.model.dit_base.final_layer.norm_final.modulation.1.weight', 'diffusion_model.model.dit_base.final_layer.norm_final.modulation.1.bias', 'diffusion_model.model.dit_base.final_layer.linear.weight', 'diffusion_model.model.dit_base.final_layer.linear.bias']
[36mStrict checkpoint loading is turned off, so using the initialized value for the missing keys.[39m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /orcd/home/002/akshatat/VisionResearch/diffusion-forcing-transformer/outputs/2026-02-14/20-20-39/wandb/offline-run-20260214_202058-xg98dhwz[0m
[1;34mwandb[0m: Find logs at: [1;35moutputs/2026-02-14/20-20-39/wandb/offline-run-20260214_202058-xg98dhwz/logs[0m

stderr (tail):
 s) in loading state_dict for DFoTVideo:
	size mismatch for diffusion_model.model.noise_level_pos_embedding.embedding.linear_1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([384, 256]).
	size mismatch for diffusion_model.model.noise_level_pos_embedding.embedding.linear_1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for diffusion_model.model.noise_level_pos_embedding.embedding.linear_2.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for diffusion_model.model.noise_level_pos_embedding.embedding.linear_2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
  File "/orcd/home/002/akshatat/VisionResearch/diffusion-forcing-transformer/experiments/base_exp.py", line 214, in validation
    trainer.validate(
  File "/home/akshatat/.conda/envs/mech_interp_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 702, in validate
    return call._call_and_handle_interrupt(
  File "/home/akshatat/.conda/envs/mech_interp_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 48, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/akshatat/.conda/envs/mech_interp_gpu/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/akshatat/.conda/envs/mech_interp_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 745, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/home/akshatat/.conda/envs/mech_interp_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1046, in _run
    self._checkpoint_connector._restore_modules_and_callbacks(ckpt_path, weights_only)
  File "/home/akshatat/.conda/envs/mech_interp_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 411, in _restore_modules_and_callbacks
    self.restore_model()
  File "/home/akshatat/.conda/envs/mech_interp_gpu/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 286, in restore_model
    self.trainer.strategy.load_model_state_dict(
  File "/home/akshatat/.conda/envs/mech_interp_gpu/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 372, in load_model_state_dict
    self.lightning_module.load_state_dict(checkpoint["state_dict"], strict=strict)
  File "/home/akshatat/.conda/envs/mech_interp_gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2635, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for DFoTVideo:
	size mismatch for diffusion_model.model.noise_level_pos_embedding.embedding.linear_1.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([384, 256]).
	size mismatch for diffusion_model.model.noise_level_pos_embedding.embedding.linear_1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for diffusion_model.model.noise_level_pos_embedding.embedding.linear_2.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for diffusion_model.model.noise_level_pos_embedding.embedding.linear_2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.


=========================================
Step 1 Complete
=========================================
Exit code: 1
End time: Sat Feb 14 20:21:05 EST 2026

Generated outputs:
total 24K
-rw-rw-r-- 1 akshatat akshatat  986 Feb 14 17:55 manifest.json
drwxrwxr-x 3 akshatat akshatat 4.0K Feb 14 15:13 sample_0000
drwxrwxr-x 3 akshatat akshatat 4.0K Feb 14 15:13 sample_0001
drwxrwxr-x 3 akshatat akshatat 4.0K Feb 14 15:13 sample_0002
drwxrwxr-x 3 akshatat akshatat 4.0K Feb 14 15:13 sample_0003
drwxrwxr-x 3 akshatat akshatat 4.0K Feb 14 15:13 sample_0004
