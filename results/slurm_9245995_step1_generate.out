=========================================
Step 1: Generate Videos with DFoT
Action-Video Mismatch Experiment
=========================================

Job ID: 9245995
Node: node3007
Start time: Sat Feb 14 20:08:09 EST 2026
GPU: 0

Python: /home/akshatat/.conda/envs/mech_interp_gpu/bin/python
Python version: Python 3.10.19

Checking GPU availability...
Sat Feb 14 20:08:12 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA L40S                    On  |   00000000:4A:00.0 Off |                    0 |
| N/A   31C    P8             33W /  350W |       0MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

=========================================
Starting DFoT video generation...
=========================================

============================================================
STEP 1: Generate videos with DFoT
============================================================

[Preflight]

[RUN]
  cwd: diffusion-forcing-transformer
  cmd: python -c import main; print('ok')
[Warn] DFOT_CHECKPOINT looks like a file/path but does not exist: DFoT_RE10K.ckpt
      If you intended pretrained name (e.g. DFoT_RE10K.ckpt), set it exactly like DFoT wiki uses.

[RUN]
  cwd: diffusion-forcing-transformer
  cmd: python -m main +name=action_mismatch_step1 dataset=realestate10k_mini algorithm=dfot_video_pose experiment=video_generation @diffusion/continuous load=pretrained:DFoT_RE10K.ckpt wandb.mode=offline wandb.entity=akshatatiwari55 ++algorithm.diffusion.training_schedule.name=cosine ++algorithm.diffusion.training_schedule.shift=0.125 ++algorithm.diffusion.loss_weighting.strategy=sigmoid ++algorithm.diffusion.loss_weighting.sigmoid_bias=-1.0 algorithm.checkpoint.strict=False experiment.tasks=[validation] experiment.validation.data.shuffle=False experiment.validation.batch_size=1 dataset.context_length=4 dataset.frame_skip=20 dataset.n_frames=12 dataset.num_eval_videos=5 algorithm.tasks.prediction.history_guidance.name=vanilla +algorithm.tasks.prediction.history_guidance.guidance_scale=4.0

[DFoT FAILED]
stdout (tail):
 [36mOutputs will be saved to:[39m /orcd/home/002/akshatat/VisionResearch/diffusion-forcing-transformer/outputs/2026-02-14/20-08-30
[36mExecuting task:[39m validation out of ['validation']
[36mThe following keys are not found in the checkpoint:[39m ['diffusion_model.model.down_blocks.2.3.conv.weight', 'diffusion_model.model.down_blocks.2.3.conv.bias']
[36mStrict checkpoint loading is turned off, so using the initialized value for the missing keys.[39m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /orcd/home/002/akshatat/VisionResearch/diffusion-forcing-transformer/outputs/2026-02-14/20-08-30/wandb/offline-run-20260214_200835-n4x4phqk[0m
[1;34mwandb[0m: Find logs at: [1;35moutputs/2026-02-14/20-08-30/wandb/offline-run-20260214_200835-n4x4phqk/logs[0m

stderr (tail):
 g a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for diffusion_model.model.mid_blocks.14.norm.norm.weight: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for diffusion_model.model.mid_blocks.14.fused_attn_mlp_proj.weight: copying a param with shape torch.Size([8064, 1152]) from checkpoint, the shape in current model is torch.Size([7168, 1024]).
	size mismatch for diffusion_model.model.mid_blocks.14.fused_attn_mlp_proj.bias: copying a param with shape torch.Size([8064]) from checkpoint, the shape in current model is torch.Size([7168]).
	size mismatch for diffusion_model.model.mid_blocks.14.q_norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for diffusion_model.model.mid_blocks.14.k_norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for diffusion_model.model.mid_blocks.14.attn_out.weight: copying a param with shape torch.Size([1152, 1152]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for diffusion_model.model.mid_blocks.14.attn_out.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for diffusion_model.model.mid_blocks.14.mlp_out.2.weight: copying a param with shape torch.Size([1152, 4608]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).
	size mismatch for diffusion_model.model.mid_blocks.14.mlp_out.2.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for diffusion_model.model.mid_blocks.15.norm.emb_layer.weight: copying a param with shape torch.Size([2304, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).
	size mismatch for diffusion_model.model.mid_blocks.15.norm.emb_layer.bias: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for diffusion_model.model.mid_blocks.15.norm.norm.weight: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for diffusion_model.model.mid_blocks.15.fused_attn_mlp_proj.weight: copying a param with shape torch.Size([8064, 1152]) from checkpoint, the shape in current model is torch.Size([7168, 1024]).
	size mismatch for diffusion_model.model.mid_blocks.15.fused_attn_mlp_proj.bias: copying a param with shape torch.Size([8064]) from checkpoint, the shape in current model is torch.Size([7168]).
	size mismatch for diffusion_model.model.mid_blocks.15.q_norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for diffusion_model.model.mid_blocks.15.k_norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for diffusion_model.model.mid_blocks.15.attn_out.weight: copying a param with shape torch.Size([1152, 1152]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for diffusion_model.model.mid_blocks.15.attn_out.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for diffusion_model.model.mid_blocks.15.mlp_out.2.weight: copying a param with shape torch.Size([1152, 4608]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).
	size mismatch for diffusion_model.model.mid_blocks.15.mlp_out.2.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([1024]).

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.


=========================================
Step 1 Complete
=========================================
Exit code: 1
End time: Sat Feb 14 20:08:38 EST 2026

Generated outputs:
total 24K
-rw-rw-r-- 1 akshatat akshatat  986 Feb 14 17:55 manifest.json
drwxrwxr-x 3 akshatat akshatat 4.0K Feb 14 15:13 sample_0000
drwxrwxr-x 3 akshatat akshatat 4.0K Feb 14 15:13 sample_0001
drwxrwxr-x 3 akshatat akshatat 4.0K Feb 14 15:13 sample_0002
drwxrwxr-x 3 akshatat akshatat 4.0K Feb 14 15:13 sample_0003
drwxrwxr-x 3 akshatat akshatat 4.0K Feb 14 15:13 sample_0004
